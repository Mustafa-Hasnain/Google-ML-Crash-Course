{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50730a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cd27a",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "tf.keras provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
    "\n",
    "Loads both the training set and the test set.\n",
    "Separates each set into features and labels.\n",
    "The relevant convenience function for MNIST is called mnist.load_data():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfa5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f33bc",
   "metadata": {},
   "source": [
    "Notice that mnist.load_data() returned four separate values:\n",
    "\n",
    "x_train contains the training set's features.\n",
    "y_train contains the training set's labels.\n",
    "x_test contains the test set's features.\n",
    "y_test contains the test set's labels.\n",
    "Note: The MNIST .csv training set is already shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c565b",
   "metadata": {},
   "source": [
    "# View the dataset\n",
    "The .csv file for the California Housing Dataset contains column names (for example, latitude, longitude, population). By contrast, the .csv file for MNIST does not contain column names. Instead of column names, you use ordinal numbers to access different subsets of the MNIST dataset. In fact, it is probably best to think of x_train and x_test as three-dimensional NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ebec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 118,\n",
       "        219, 166, 118, 118,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 242, 254,\n",
       "        254, 254, 254, 254,  66,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 232, 254,\n",
       "        254, 254, 254, 254, 238,  70,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 244,\n",
       "        254, 224, 254, 254, 254, 141,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207,\n",
       "        254, 210, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84,\n",
       "        206, 254, 254, 254, 254,  41,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         24, 209, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  91,\n",
       "        137, 253, 254, 254, 254, 112,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 214, 250,\n",
       "        254, 254, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 247, 254,\n",
       "        254, 254, 254, 254, 254, 146,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 246,\n",
       "        254, 254, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  73,\n",
       "         89,  89,  93, 240, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1, 128, 254, 219,  31,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   7, 254, 254, 214,  28,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 138, 254, 254, 116,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  19, 177,  90,   0,   0,   0,   0,\n",
       "          0,  25, 240, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 164, 254, 215,  63,  36,   0,  51,\n",
       "         89, 206, 254, 254, 139,   8,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  57, 197, 254, 254, 222, 180, 241,\n",
       "        254, 254, 253, 213,  11,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 105, 254, 254, 254, 254,\n",
       "        254, 254, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 117, 117, 165, 254,\n",
       "        254, 239,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25edae1",
   "metadata": {},
   "source": [
    "# Alternatively, you can call matplotlib.pyplot.imshow to interpret the preceding numeric array as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446ae0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2dcd0ace400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce82cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output row #10 of example #2917.\n",
    "x_train[2917][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905a0ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output pixel #16 of row #10 of example #2900.\n",
    "x_train[2917][10][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98feeb58",
   "metadata": {},
   "source": [
    "# Task 1: Normalize feature values\n",
    "Complete the following code cell to map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. Store the floating-point values in x_train_normalized and x_test_normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2cd991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.55294118 1.         0.66666667 0.11372549 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "x_train_normalized = x_train/255.0\n",
    "x_test_normalized = x_test/255.0\n",
    "print(x_train_normalized[2900][10]) # Output a normalized row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d8f1c",
   "metadata": {},
   "source": [
    "# Create a deep neural net model\n",
    "The create_model function defines the topography of the deep neural net, specifying the following:\n",
    "\n",
    "The number of layers in the deep neural net.\n",
    "The number of nodes in each layer.\n",
    "Any regularization layers.\n",
    "The create_model function also defines the activation function of each layer. The activation function of the output layer is softmax, which will yield 10 different outputs for each example. Each of the 10 outputs provides the probability that the input example is a certain digit.\n",
    "\n",
    "Note: Unlike several of the recent Colabs, this exercise does not define feature columns or a feature layer. Instead, the model will train on the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b798f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate):#here feature layer will not be used like other exercises\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a a one-dimensional \n",
    "  # 784-element array.\n",
    "    model.add(tf.keras.layers.Flatten(input_shape = (28, 28)))\n",
    "    \n",
    "    # Define the first hidden layer.   \n",
    "    model.add(tf.keras.layers.Dense(units = 32, activation = \"relu\"))\n",
    "    \n",
    "    #Define a Deopout regulization layer\n",
    "    model.add(tf.keras.layers.Dropout(rate =0.2))\n",
    "    \n",
    "    # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "    model.add(tf.keras.layers.Dense(units = 32, activation = \"softmax\"))\n",
    "    \n",
    "    # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Now to Train Model\n",
    "def train_model(model, train_features, train_label ,epochs, batch_size,validation_split = 0.1):\n",
    "    history = model.fit(x= train_features, y = train_label, epochs = epochs, batch_size = batch_size ,validation_split= validation_split)\n",
    "     # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    \n",
    "    return epochs, hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6150e",
   "metadata": {},
   "source": [
    "# Define a plotting function\n",
    "The following function plots an accuracy curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94efbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrices):\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    \n",
    "    for i in list_of_metrices:\n",
    "        x = hist[i]\n",
    "        plt.plot(epochs[1:], x[1: ], label = i)\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d597f",
   "metadata": {},
   "source": [
    "# Invoke the previous functions\n",
    "Run the following code cell to invoke the preceding functions and actually train the model on the training set.\n",
    "\n",
    "Note: Due to several factors (for example, more examples and a more complex neural network) training MNIST might take longer than training the California Housing Dataset. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbdd2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 2.5169 - accuracy: 0.2399 - val_loss: 1.5399 - val_accuracy: 0.6104\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.3667 - accuracy: 0.5882 - val_loss: 0.8263 - val_accuracy: 0.8034\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.9026 - accuracy: 0.7241 - val_loss: 0.5680 - val_accuracy: 0.8547\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.6924 - accuracy: 0.7925 - val_loss: 0.4490 - val_accuracy: 0.8818\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5796 - accuracy: 0.8279 - val_loss: 0.3843 - val_accuracy: 0.8974\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5123 - accuracy: 0.8475 - val_loss: 0.3451 - val_accuracy: 0.9047\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4667 - accuracy: 0.8641 - val_loss: 0.3177 - val_accuracy: 0.9128\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4338 - accuracy: 0.8720 - val_loss: 0.2985 - val_accuracy: 0.9187\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4091 - accuracy: 0.8831 - val_loss: 0.2854 - val_accuracy: 0.9211\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.3925 - accuracy: 0.8843 - val_loss: 0.2728 - val_accuracy: 0.9254\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3788 - accuracy: 0.8890 - val_loss: 0.2629 - val_accuracy: 0.9272\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.3650 - accuracy: 0.8932 - val_loss: 0.2540 - val_accuracy: 0.9297\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.3574 - accuracy: 0.8956 - val_loss: 0.2479 - val_accuracy: 0.9313\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3437 - accuracy: 0.9009 - val_loss: 0.2407 - val_accuracy: 0.9332\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.3382 - accuracy: 0.9015 - val_loss: 0.2346 - val_accuracy: 0.9352\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.3284 - accuracy: 0.9051 - val_loss: 0.2294 - val_accuracy: 0.9368\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3236 - accuracy: 0.9054 - val_loss: 0.2251 - val_accuracy: 0.9369\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3143 - accuracy: 0.9076 - val_loss: 0.2202 - val_accuracy: 0.9382\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3081 - accuracy: 0.9096 - val_loss: 0.2165 - val_accuracy: 0.9391\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2994 - accuracy: 0.9115 - val_loss: 0.2121 - val_accuracy: 0.9398\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2980 - accuracy: 0.9126 - val_loss: 0.2088 - val_accuracy: 0.9413\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2899 - accuracy: 0.9149 - val_loss: 0.2044 - val_accuracy: 0.9421\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2859 - accuracy: 0.9162 - val_loss: 0.2014 - val_accuracy: 0.9427\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.2807 - accuracy: 0.9182 - val_loss: 0.1977 - val_accuracy: 0.9442\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2755 - accuracy: 0.9182 - val_loss: 0.1956 - val_accuracy: 0.9436\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2741 - accuracy: 0.9191 - val_loss: 0.1931 - val_accuracy: 0.9448\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.2664 - accuracy: 0.9213 - val_loss: 0.1897 - val_accuracy: 0.9459\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2672 - accuracy: 0.9195 - val_loss: 0.1877 - val_accuracy: 0.9462\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2625 - accuracy: 0.9215 - val_loss: 0.1857 - val_accuracy: 0.9467\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2581 - accuracy: 0.9230 - val_loss: 0.1831 - val_accuracy: 0.9478\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2527 - accuracy: 0.9254 - val_loss: 0.1817 - val_accuracy: 0.9483\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2501 - accuracy: 0.9258 - val_loss: 0.1798 - val_accuracy: 0.9484\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2496 - accuracy: 0.9261 - val_loss: 0.1773 - val_accuracy: 0.9492\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.2469 - accuracy: 0.9266 - val_loss: 0.1762 - val_accuracy: 0.9497\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2425 - accuracy: 0.9273 - val_loss: 0.1746 - val_accuracy: 0.9503\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2394 - accuracy: 0.9287 - val_loss: 0.1725 - val_accuracy: 0.9504\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2360 - accuracy: 0.9296 - val_loss: 0.1707 - val_accuracy: 0.9515\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2343 - accuracy: 0.9305 - val_loss: 0.1700 - val_accuracy: 0.9513\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2304 - accuracy: 0.9306 - val_loss: 0.1685 - val_accuracy: 0.9522\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2315 - accuracy: 0.9301 - val_loss: 0.1674 - val_accuracy: 0.9516\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2260 - accuracy: 0.9311 - val_loss: 0.1654 - val_accuracy: 0.9523\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.93 - 0s 23ms/step - loss: 0.2285 - accuracy: 0.9304 - val_loss: 0.1646 - val_accuracy: 0.9529\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2244 - accuracy: 0.9325 - val_loss: 0.1658 - val_accuracy: 0.9517\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2234 - accuracy: 0.9331 - val_loss: 0.1634 - val_accuracy: 0.9526\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2196 - accuracy: 0.9335 - val_loss: 0.1615 - val_accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2174 - accuracy: 0.9348 - val_loss: 0.1611 - val_accuracy: 0.9538\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2151 - accuracy: 0.9346 - val_loss: 0.1600 - val_accuracy: 0.9540\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2138 - accuracy: 0.9368 - val_loss: 0.1585 - val_accuracy: 0.9544\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2132 - accuracy: 0.9354 - val_loss: 0.1590 - val_accuracy: 0.9554\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2118 - accuracy: 0.9365 - val_loss: 0.1569 - val_accuracy: 0.9548\n",
      "\n",
      "Evaluating Against Test Set\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1609 - accuracy: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16085460782051086, 0.9550999999046326]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The hypermeters\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "#Creating the model\n",
    "\n",
    "my_model = create_model(learning_rate)\n",
    "\n",
    "#training The model\n",
    "\n",
    "epochs, hist = train_model(my_model, x_train_normalized, y_train, epochs, batch_size, validation_split)\n",
    "\n",
    "metrics = [\"accuracy\"]\n",
    "plot_curve(epochs, hist, metrics)\n",
    "\n",
    "#Evaluatng against Test Set\n",
    "print(\"\\nEvaluating Against Test Set\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7636f",
   "metadata": {},
   "source": [
    "# Task 2: Optimize the model\n",
    "Experiment with the following:\n",
    "\n",
    "number of hidden layers\n",
    "number of nodes in each layer\n",
    "dropout regularization rate\n",
    "What trends did you discover? Can you reach at least 98% accuracy against the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64846148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would take much too long to experiment \n",
    "# fully with topography and dropout regularization \n",
    "# rate. In the real world, you would\n",
    "# also experiment with learning rate, batch size, \n",
    "# and number of epochs.  Since you only have a \n",
    "# few minutes, searching for trends can be helpful.\n",
    "# Here is what we discovered:\n",
    "#   * Adding more nodes (at least until 256 nodes) \n",
    "#     to the first hidden layer improved accuracy.\n",
    "#   * Adding a second hidden layer generally \n",
    "#     improved accuracy.\n",
    "#   * When the model contains a lot of nodes, \n",
    "#     the model overfits unless the dropout rate \n",
    "#     is at least 0.5. \n",
    "\n",
    "# We reached 98% test accuracy with the \n",
    "# following configuration:\n",
    "#   * One hidden layer of 256 nodes; no second hidden layer.\n",
    "#   * dropout regularization rate of 0.4\n",
    "\n",
    "# We reached 98.2% test accuracy with the \n",
    "# following configuration:\n",
    "#   * First hidden layer of 256 nodes; \n",
    "#     second hidden layer of 128 nodes.\n",
    "#   * dropout regularization rate of 0.2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
